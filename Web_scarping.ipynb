{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bienvenue dans Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morokhalid16/2020-ISblue-Course-on-Big-Data-Science-IMT-A-ENSTA-IUEM-/blob/master/Web_scarping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>Qu'est-ce que Colaboratory ?</h1>\n",
        "\n",
        "Colaboratory, souvent raccourci en \"Colab\", vous permet d'écrire et d'exécuter du code Python dans votre navigateur, avec \n",
        "- Aucune configuration requise\n",
        "- Accès gratuit aux GPU\n",
        "- Partage facile\n",
        "\n",
        "Que vous soyez <strong>étudiant</strong>, <strong>data scientist</strong> ou <strong>chercheur en IA</strong>, Colab peut rendre votre travail plus simple. Regardez la <a href=\"https://www.youtube.com/watch?v=inN8seMm7UI\">présentation de Colab</a> pour en savoir plus ou faites vos premiers pas ci-dessous !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0js1WzPMxVfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiNM-N2LxV7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collect first page of artists’ list\n",
        "page = requests.get('https://web.archive.org/web/20121007172955/https://www.nga.gov/collection/anZ1.htm')\n",
        "# Create a BeautifulSoup object\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "last_links = soup.find(class_='AlphaNav')\n",
        "last_links.decompose()\n",
        "\n",
        "# Create a file to write to, add headers row\n",
        "f = csv.writer(open('z-artist-names.csv', 'w'))\n",
        "f.writerow(['Name', 'Link'])\n",
        "\n",
        "\n",
        "# Pull all text from the BodyText div\n",
        "artist_name_list = soup.find(class_='BodyText')\n",
        "# Pull text from all instances of <a> tag within BodyText div\n",
        "artist_name_list_items = artist_name_list.find_all('a')\n",
        "# Create for loop to print out all artists' names\n",
        "for artist_name in artist_name_list_items:\n",
        "    #print(artist_name.prettify())\n",
        "    names = artist_name.contents[0]\n",
        "    links = 'https://web.archive.org' + artist_name.get('href')\n",
        "    #print(names)\n",
        "    #print(links)\n",
        "    # Add each artist’s name and associated link to a row\n",
        "    f.writerow([names, links])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo-SJgDg3z2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pages = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "    url = 'https://web.archive.org/web/20121007172955/https://www.nga.gov/collection/anZ' + str(i) + '.htm'\n",
        "    pages.append(url)\n",
        "\n",
        "for item in pages:\n",
        "    page = requests.get(item)\n",
        "    soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "    last_links = soup.find(class_='AlphaNav')\n",
        "    last_links.decompose()\n",
        "\n",
        "    artist_name_list = soup.find(class_='BodyText')\n",
        "    artist_name_list_items = artist_name_list.find_all('a')\n",
        "\n",
        "    for artist_name in artist_name_list_items:\n",
        "        names = artist_name.contents[0]\n",
        "        links = 'https://web.archive.org' + artist_name.get('href')\n",
        "\n",
        "        f.writerow([names, links])"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}